{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Q1: Probabilistic N-Gram Language Model(50 points)"
      ],
      "metadata": {
        "id": "a4NQTign_k_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "The objective of this question is to implement and experiment with an N-Gram language model using the Reuters dataset. The task involves building a probabilistic N-Gram model and creating a text generator based on the trained model with customizable parameters.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "\n",
        "**1.Text Preprocessing (5 points):**\n",
        "*   Implement the preprocess_text function to perform necessary text preprocessing. You may use NLTK or other relevant libraries for this task. (Already provided, no modification needed)\n",
        "\n",
        "\n",
        "**2.Build Probabilistic N-Gram Model (15 points):**\n",
        "\n",
        "*   Implement the build_probabilistic_ngram_model function to construct a probabilistic N-Gram model from the Reuters dataset.\n",
        "\n",
        "\n",
        "**3.Generate Text with Customizable Parameters (15 points):**\n",
        "\n",
        "*   Implement the generate_text function to generate text given a seed text and the probabilistic N-Gram model.\n",
        "*   The function should have parameters for probability_threshold and min_length to customize the generation process.\n",
        "*   Ensure that the generation stops when either the specified min_length is reached or the probabilities fall below probability_threshold.\n",
        "\n",
        "\n",
        "**4.Experimentation and Parameter Tuning (5 points):**\n",
        "\n",
        "*   Use Google Colab to experiment with different values of n_value, probability_threshold, and min_length.\n",
        "Find the optimal parameters that result in coherent and meaningful generated text.\n",
        "*   Provide a detailed analysis of the impact of changing each parameter on the generated text's quality.\n",
        "*   Discuss any challenges faced during parameter tuning and propose potential improvements.\n",
        "\n",
        "\n",
        "**5.Results and Conclusion (10 points):**\n",
        "\n",
        "*   Summarize your findings and present the optimal parameter values for n_value, probability_threshold, and min_length.\n",
        "*   Discuss the trade-offs and considerations when selecting these parameters.\n",
        "*   Conclude with insights gained from the experimentation."
      ],
      "metadata": {
        "id": "zDKtnG-HAH1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk import ngrams\n",
        "import random\n",
        "import string\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Download the Reuters dataset if not already downloaded\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "3NWXJy-T-Vd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff7ac32-aec5-4ef6-b5a8-001a03ff8d0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q9IHxAbU0N80"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Fill in: Implement text preprocessing steps like lowercasing, removing punctuation, etc.\n",
        "    # You may use NLTK or other libraries for this.\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# print(\"testing preprocessing:\")\n",
        "# text_example = \"The Quick Brown Fox , is Jumping Over The rabbit.\"\n",
        "# preprocessed_text = preprocess_text(text_example)\n",
        "# print(preprocessed_text)\n",
        "\n",
        "# Function to build a probabilistic n-gram model\n",
        "def build_probabilistic_ngram_model(corpus, n):\n",
        "    # Fill in: Implement code to build an n-gram model from the given corpus.\n",
        "    # You may use NLTK's word_tokenize function.\n",
        "\n",
        "    n_gram_probabilities = defaultdict(dict)\n",
        "\n",
        "    # Generate all tokens from the corpus\n",
        "    # allTokens = [token for doc in corpus for token in doc]\n",
        "\n",
        "    # Iterate over each document in the corpus to build the n-gram model\n",
        "    for tokens in corpus:\n",
        "        n_grams = list(ngrams(tokens, n))\n",
        "        n_minus_1_grams = list(ngrams(tokens, n-1))\n",
        "\n",
        "        n_gram_counts = Counter(n_grams)\n",
        "        n_minus_1_gram_counts = Counter(n_minus_1_grams)\n",
        "\n",
        "        # Calculate probabilities without Laplace smoothing\n",
        "        for n_gram in n_gram_counts:\n",
        "            prefix = n_gram[:-1]\n",
        "            word = n_gram[-1]\n",
        "            # Calculate probability without adding vocabulary size for smoothing\n",
        "            probability = n_gram_counts[n_gram] / n_minus_1_gram_counts[prefix]\n",
        "            n_gram_probabilities[prefix][word] = probability\n",
        "    return n_gram_probabilities\n",
        "\n",
        "def generate_text(model, seed_text, n, probability_threshold=0.02, min_length=8):\n",
        "    generated_text = preprocess_text(seed_text)\n",
        "    current_length = len(generated_text)\n",
        "\n",
        "    while current_length < min_length:\n",
        "        # Get the last n-1 words as the current context\n",
        "        context = tuple(generated_text[-(n-1):])\n",
        "\n",
        "        # Check if the context exists in the model\n",
        "        if context in model:\n",
        "            possible_words = list(model[context].items())\n",
        "            # Sort words by their probability in descending order\n",
        "            possible_words.sort(key=lambda x: x[1], reverse=True)\n",
        "            # Filter out words based on the probability threshold\n",
        "            possible_words = [word for word in possible_words if word[1] >= probability_threshold]\n",
        "            if not possible_words:\n",
        "                break  # If no words meet the threshold, stop the generation\n",
        "\n",
        "            # Randomly select a word from the filtered list based on their probabilities\n",
        "            next_word = random.choices([word[0] for word in possible_words], [word[1] for word in possible_words])[0]\n",
        "            generated_text.append(next_word)\n",
        "            current_length += 1\n",
        "        else:\n",
        "            break  # If the context is not found in the model, stop the generation\n",
        "\n",
        "    return ' '.join(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the Reuters dataset\n",
        "corpus = [reuters.raw(file_id) for file_id in reuters.fileids()]\n",
        "\n",
        "# Preprocess the entire corpus\n",
        "preprocessed_corpus = [preprocess_text(text) for text in corpus]\n",
        "\n",
        "# Choose an n for the n-gram model\n",
        "n_value = 3  # You may change this value\n",
        "\n",
        "# print(preprocessed_corpus[:4])\n",
        "probabilistic_ngram_model = build_probabilistic_ngram_model(preprocessed_corpus, n_value)\n",
        "# print (probabilistic_ngram_model)\n",
        "seed_text = \"Inflation is\"\n",
        "\n",
        "# for n_value in range (2, 10):\n",
        "print(\"n is: \", n_value)\n",
        "# Build the probabilistic n-gram model\n",
        "# probabilistic_ngram_model = build_probabilistic_ngram_model(preprocessed_corpus, n_value)\n",
        "generated_text = generate_text(probabilistic_ngram_model, seed_text, n_value, probability_threshold=0.02, min_length=8)\n",
        "print(f\"Generated Text: {generated_text}\")\n",
        "seed_text = generated_text\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eVVMe_s59Ngd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7a6787-a94d-4a88-9138-5d05dfc55276"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n is:  3\n",
            "Generated Text: inflation is expected to know their ships final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ngram_performance(corpus, ngram_values, probability_thresholds, minimum_lengths):\n",
        "    max_text_length = -1  # Reflects the maximum length of generated text\n",
        "    optimal_params = None  # To hold the best configuration\n",
        "\n",
        "    for ngram_size in ngram_values:\n",
        "        for threshold in probability_thresholds:\n",
        "            for min_length in minimum_lengths:\n",
        "                model = build_probabilistic_ngram_model(corpus, ngram_size)\n",
        "                total_text_length = 0  # Sum of lengths of generated texts\n",
        "\n",
        "                # Seed texts for generating new text to evaluate the model\n",
        "                for seed_text in [\"Inflation is\", \"The weather\"]:\n",
        "                    generated_text = generate_text(model, seed_text, ngram_size, threshold, min_length)\n",
        "                    print(f\"Generated Text: {generated_text}\")\n",
        "                    total_text_length += len(generated_text.split())\n",
        "\n",
        "                if total_text_length > max_text_length:\n",
        "                    max_text_length = total_text_length\n",
        "                    optimal_params = (ngram_size, threshold, min_length)\n",
        "\n",
        "    return optimal_params\n",
        "\n",
        "best_n, best_threshold, best_min_length = evaluate_ngram_performance(\n",
        "    preprocessed_corpus,\n",
        "    ngram_values=[2,3,4,5],\n",
        "    probability_thresholds=[0.02, 0.05, 0.1, 0.5, 1],\n",
        "    minimum_lengths=[20, 10, 8, 5]\n",
        ")\n",
        "\n",
        "print(f\"Best Parameters: n={best_n}, threshold={best_threshold}, min_length={best_min_length}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJqy8J3s-4rA",
        "outputId": "dacfd68a-9948-4ec1-d4c4-b59a88f29dcb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text: inflation is clear import levies affect earnings endusers can stay firm waterman acquisition ltnew milford savings ltfambo 3rd term significance\n",
            "Generated Text: the weather slack from july 21 will retire in santos the 43dlrashare offer 25 this ceiling by greek industry achieved\n",
            "Generated Text: inflation is reached reasonably well enable its biannual opec boosted\n",
            "Generated Text: the weather manufacturing base larger new airline has provoked us\n",
            "Generated Text: inflation is 3734 us remained firm linked with\n",
            "Generated Text: the weather delaying approval calls report qualified due\n",
            "Generated Text: inflation is isthmus pay 40\n",
            "Generated Text: the weather despite suppositions to\n",
            "Generated Text: inflation is renewing its flexible pricing period yincludes ill was instead with 2519 in defense electronics gtx statement later alfaro\n",
            "Generated Text: the weather manufacturing base was muted as real run until their side effect as taiwan the 3491030 new acting to\n",
            "Generated Text: inflation is lmes first battle however volcker pushes spending said\n",
            "Generated Text: the weather is consistent diseaseresistant seed 84 rupees effective capital\n",
            "Generated Text: inflation is 80 individual claims rose 88 batus\n",
            "Generated Text: the weather in air attacks in life experts\n",
            "Generated Text: inflation is dependent nonbanks fell\n",
            "Generated Text: the weather reports sharp criticism\n",
            "Generated Text: inflation is essential covenants set in ccx inc holds now must boost prices since may 1987october 1988 to moonie oil\n",
            "Generated Text: the weather both a smoke were twothirds above profits taking advantage as reductions were 469100 tonnes unless drilling to announced\n",
            "Generated Text: inflation is typically allow slightly firmer longterm damage to unload\n",
            "Generated Text: the weather apparel store co ltnsp votes credit demand for\n",
            "Generated Text: inflation is applicable because monetary course anxious to\n",
            "Generated Text: the weather added mcivor said extensive drill below\n",
            "Generated Text: inflation is presenting the network\n",
            "Generated Text: the weather apparel merchandise group\n",
            "Generated Text: inflation is under grace at 8324 billion taiwan because asian refiners worked a 10k report mcm said mim canada consumer\n",
            "Generated Text: the weather report positive economic community currencies apart to seismic program gartner group chairman graeme odgers said shops on 1825\n",
            "Generated Text: inflation is group might point will return in wellsville amity\n",
            "Generated Text: the weather another problem its crippling budget keating economist sees\n",
            "Generated Text: inflation is therefore company stressed bonn was 145900\n",
            "Generated Text: the weather remains much producers federation at increased\n",
            "Generated Text: inflation is chiefly interested countries\n",
            "Generated Text: the weather another positive private\n",
            "Generated Text: inflation is privatised by county ohio shopping days based i do its boatmens\n",
            "Generated Text: the weather in stores inoperation at uk lex\n",
            "Generated Text: inflation is 800000 last regulatory agenda van schaik said agreement\n",
            "Generated Text: the weather delaying until may act as acting prime national\n",
            "Generated Text: inflation is practicable date book at restrictive rice\n",
            "Generated Text: the weather sales 150 cts payable 295 bcf\n",
            "Generated Text: inflation is 999 mln punts\n",
            "Generated Text: the weather had used the\n",
            "Generated Text: inflation is expected at tomorrows regular central bank aid as a steward of a feasibility report from us and related\n",
            "Generated Text: the weather was wetter and some brazils they said and unlike the speculators said john curti an analyst at best\n",
            "Generated Text: inflation is not selling as well hockin said he reserves\n",
            "Generated Text: the weather bureau said this board will lift its decision\n",
            "Generated Text: inflation is likely it would curb their exports\n",
            "Generated Text: the weather is favourable to his planned subsidy\n",
            "Generated Text: inflation is not setting any\n",
            "Generated Text: the weather was wetter and\n",
            "Generated Text: inflation is for our future connunications audiences and of coheads morgan guaranty said banks paid back and see attitude by\n",
            "Generated Text: the weather on several years to the currency jumped to 783 pct from 186 pct last week makumbi blamed the\n",
            "Generated Text: inflation is expected at budget time he said volcker said\n",
            "Generated Text: the weather was wetter and some officers of endotronics endotronics\n",
            "Generated Text: inflation is expected lower but oat sowings could\n",
            "Generated Text: the weather up to 328 mln avg 69\n",
            "Generated Text: inflation is behind us and\n",
            "Generated Text: the weather up to start\n",
            "Generated Text: inflation is running around a few other nations are heading into a final opportunity to signal an end otherwise the\n",
            "Generated Text: the weather on several factors the government then began importing refined sugar rigaud said hascos closing at 7658 cts wednesday\n",
            "Generated Text: inflation is the parent holds a contract packager of personal\n",
            "Generated Text: the weather up to japans advantage it would operate as\n",
            "Generated Text: inflation is a major drop in market for\n",
            "Generated Text: the weather up to serve clients in europe\n",
            "Generated Text: inflation is likely that earnings\n",
            "Generated Text: the weather bureau said this\n",
            "Generated Text: inflation is cut by five to six cts pay march 26 canbra said it noted morgan said some banks may\n",
            "Generated Text: the weather bureau said but representatives from thailand of the agreements mr rooter said it fixed the won rose by\n",
            "Generated Text: inflation is likely said paul sheen chairman of argosystems shares\n",
            "Generated Text: the weather is likely in canada the stateowned oil organisation\n",
            "Generated Text: inflation is cut these analysts argue prices will\n",
            "Generated Text: the weather up to president corazon aquino from\n",
            "Generated Text: inflation is for 17 months\n",
            "Generated Text: the weather is usually more\n",
            "Generated Text: inflation is expected here on april 21 to shareholders 75 mln revs 39 billion cubic metres produced in eastern and\n",
            "Generated Text: the weather is usually active after the stock from 1930734 shares or 36 cts net 1101000 vs 901000 year shr\n",
            "Generated Text: inflation is running at over five pct above an expected\n",
            "Generated Text: the weather on several key areas at present astra stock\n",
            "Generated Text: inflation is a big difference on other major\n",
            "Generated Text: the weather on several factors the largest credit\n",
            "Generated Text: inflation is for our operations\n",
            "Generated Text: the weather is usually active\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Generated Text: inflation is\n",
            "Generated Text: the weather\n",
            "Best Parameters: n=2, threshold=0.02, min_length=20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***faced challenges:***\n",
        "* passing the right compatible data types to functions.\n",
        "* text was not being generated with some probability_threshold like 1.\n",
        "* probability calculation can be improved by using Laplace smoothing."
      ],
      "metadata": {
        "id": "JlJuplyv7nU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q2: Sentiment Analysis with Naive Bayes Classifier(50 Points)"
      ],
      "metadata": {
        "id": "dZ3XzDx7JUNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective:**\n",
        "\n",
        "You are tasked with implementing a Naive Bayes classifier for sentiment analysis. The provided code is incomplete, and your goal is to complete the missing parts. Additionally, you should train the classifier on a small dataset and analyze its performance.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1.**Complete the Code (35 points)**: Fill in the missing parts in the provided Python code for the Naive Bayes classifier. Pay special attention to the `extract_features` function.\n",
        "\n",
        "2.**Train and Test**: Train the Naive Bayes classifier on the training data and test it on a separate test set. Evaluate the accuracy of the classifier.\n",
        "\n",
        "3.**Analysis (15 points)**: Discuss the results. Identify any misclassifications and try to understand why the classifier may fail in those cases. Provide examples of sentences that were not predicted correctly and explain possible reasons.\n"
      ],
      "metadata": {
        "id": "NMuVkjW2XfAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import string\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import movie_reviews\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "M68XJubdKeDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707128b8-ac58-47c8-8985-43f196614f85"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(tokens):\n",
        "    # Remove punctuation\n",
        "    tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Perform stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "KSLo4_JoUcax"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, classes):\n",
        "        self.classes = classes\n",
        "        self.class_probs = defaultdict(float)\n",
        "        self.feature_probs = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "        # adding feature count and class count to the class definition because of usage\n",
        "        self.feature_counts = defaultdict(lambda: defaultdict(float))\n",
        "        self.class_counts = defaultdict(float)\n",
        "\n",
        "    def train(self, training_data):\n",
        "        total_docs = len(training_data)\n",
        "        for tokens, class_ in training_data:\n",
        "            features = get_features(tokens)\n",
        "            self.class_counts[class_] += 1\n",
        "            for feature in features:\n",
        "                self.feature_counts[feature][class_] += 1\n",
        "\n",
        "        # calculate class probabilities and using logarithm for easier calculation\n",
        "        for c in self.classes:\n",
        "            self.class_probs[c] = log(self.class_counts[c] / total_docs)\n",
        "\n",
        "        # feature probabilities\n",
        "        for feature, class_counts in self.feature_counts.items():\n",
        "            for c in self.classes:\n",
        "                # apply Laplace smoothing assuming binary featurs (0 or 1)\n",
        "                self.feature_probs[feature][c] = log((class_counts[c] + 1) / (self.class_counts[c] + 2))\n",
        "\n",
        "    def classify(self, features):\n",
        "        max_class = None\n",
        "        max_prob = float('-inf')\n",
        "        # calculate the log probabilities for each class based on the features\n",
        "        for class_ in self.classes:\n",
        "            prob = self.class_probs[class_]\n",
        "            for feature in get_features(features):\n",
        "                prob += self.feature_probs[feature].get(class_, log(1 / (self.class_counts[class_] + 2)))\n",
        "            if prob > max_prob:\n",
        "                max_prob = prob\n",
        "                max_class = class_\n",
        "        return max_class\n"
      ],
      "metadata": {
        "id": "RGmeKXE51sc0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the movie reviews dataset from NLTK\n",
        "data = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "random.shuffle(data)\n",
        "\n",
        "# Shuffle the dataset for randomness\n",
        "random.shuffle(data)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(data) * split_ratio)\n",
        "train_set = data[:split_index]\n",
        "test_set = data[split_index:]\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "classes = set(sentiment for _, sentiment in train_set)\n",
        "classifier = NaiveBayesClassifier(classes)\n",
        "classifier.train(train_set)\n",
        "\n",
        "def calculate_accuracy(dataset, dataset_type):\n",
        "    # Test the classifier on the testing set\n",
        "    correct_predictions = 0\n",
        "    for example in dataset:\n",
        "        tokens, true_sentiment = example\n",
        "        features = get_features(tokens)\n",
        "        predicted_sentiment = classifier.classify(features)\n",
        "        if predicted_sentiment == true_sentiment:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / len(dataset)\n",
        "    print(f\"{dataset_type} Accuracy: {accuracy}\")\n",
        "\n",
        "calculate_accuracy(train_set, 'Train')\n",
        "calculate_accuracy(test_set, 'Test')"
      ],
      "metadata": {
        "id": "j2jeyI6nKooE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa33d60-0a08-4d2f-9565-543f7d1496f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.895\n",
            "Test Accuracy: 0.6975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submission Instructions:\n"
      ],
      "metadata": {
        "id": "Nfl8UA42Gqjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "3.Clearly present the results of your parameter tuning in the notebook.\n",
        "\n",
        "4.Provide a brief summary of your findings and insights in the conclusion section.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Experiment with various seed texts to showcase the diversity of generated text.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ],
      "metadata": {
        "id": "75kVTQX6GsCn"
      }
    }
  ]
}